{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computer Vision is a field of study that seeks to develop computers to 'see' i.e visualize real world in the form of images, videos.\n",
    "\n",
    "In this notebook, we attempt to teach computers to read house numbers that were captured by Google street view cars. These house numbers come in all shapes and sizes, our model should be intelligent enough to remove the noise from the image that may have crept in and identify numbers accurately.\n",
    "**\n",
    "\n",
    "We would demonstrate 2 approaches:\n",
    "* Fully Connected Network\n",
    "* Convolutional Neural Network\n",
    "\n",
    "**Code Structure:**\n",
    "* Import packages, Visualize dataset\n",
    "* Pre-process the input to be fit into the model\n",
    "* Build Fully Connected Network\n",
    "* Build Convolutional Neural Network\n",
    "* Check Model accuracy\n",
    "* Visualize Model predictions\n",
    "\n",
    "*Special thanks to: https://machinelearningmastery.com/what-is-computer-vision/* This is a treasure trove of everything on Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "!pip install tensorboardcolab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "h5f = h5py.File('/kaggle/input/street-view-house-nos-h5-file/SVHN_single_grey1.h5', 'r')\n",
    "h5f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "\n",
    "h5f.close() #close this file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To understand the breadth and depth of the data, lets check shape of data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('X_test:', X_train.shape)\n",
    "print('y_test:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Showing the first 100 test images, we have to build a model that would classify these images accurately. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "rows = 10\n",
    "columns = 10\n",
    "w = 10\n",
    "h = 10\n",
    "\n",
    "for i in range(1, rows * columns + 1):\n",
    "    img = X_test[i]\n",
    "    fig.add_subplot(rows, columns,i)\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 2 approaches to classify these images.\n",
    "* Fully Connected Network\n",
    "* Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For FC, Keras expects data to be in the format of **No. of Examples, Height * Width**\n",
    "\n",
    "For CNN, Keras expects data to be in the format of **No. of Examples, Height, Width, No. of Channels**\n",
    "\n",
    "Therefore, we have to reshape the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape) #before reshape\n",
    "img_rows, img_cols = 32,32 #capturing this separately to be used later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Fully Connected Network\n",
    "X_train_FC = X_train.reshape(X_train.shape[0], img_rows * img_cols) #32*32\n",
    "X_test_FC = X_test.reshape(X_test.shape[0], img_rows * img_cols)\n",
    "print(X_train_FC.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Convolutional Neural Network\n",
    "X_train_CNN = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_train_CNN.shape\n",
    "X_test_CNN = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "print(X_train_CNN.shape)\n",
    "\n",
    "#Shape of 1 image would be as given below, this would be useful while creating models\n",
    "input_shape  = (img_rows, img_cols, 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reshaped the images into format as accepted by Keras. Lets see what constitutes the training data, its a long list of arrays as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_FC[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CNN[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to preprocess this i.e normalize the input. This ensures none of the columns would dominate the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For FC Network\n",
    "X_train_FC = X_train_FC.astype('float32')\n",
    "X_test_FC =  X_test_FC.astype('float32')\n",
    "\n",
    "#Normalizing the input\n",
    "X_train_FC = X_train_FC / 255.0\n",
    "X_test_FC = X_test_FC / 255.0\n",
    "\n",
    "print(X_train_FC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_FC.max() #This is to cross check whether inputs have been normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For CNN \n",
    "X_train_CNN = X_train_CNN.astype('float32')\n",
    "X_test_CNN =  X_test_CNN.astype('float32')\n",
    "\n",
    "#Normalizing the input\n",
    "X_train_CNN = X_train_CNN / 255.0\n",
    "X_test_CNN = X_test_CNN / 255.0\n",
    "\n",
    "print(X_train_CNN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CNN.max() #This is to cross check whether inputs have been normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have normalized the input, lets check whether y_train are in the right format to be inserted into the model or not. As we observe below, it needs to be converted into One Hot Encoding vectors. Else it would lead to one of the column dominating the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "#convert class vectors to binary class metrics\n",
    "num_classes = 10 # since we will only classify nos between 0-9\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "model_FC = Sequential()\n",
    "model_FC.add(Dense(100, input_shape = (1024, ), activation = 'relu')) #hidden layer\n",
    "model_FC.add(Dense(10, activation = 'softmax')) #output layer\n",
    "model_FC.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to set 3 things: \n",
    "\n",
    "**\n",
    "* Loss function\n",
    "* Optimizers\n",
    "* Metrics\n",
    "**\n",
    "\n",
    "Think of it as Car is ready, to drive it around we need Keys, Fuel et all.. just like that these 3 things are very important for the model to learn and correct itself. This is the essence of Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FC.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model_FC.fit(X_train_FC, y_train, batch_size = 128, epochs = 10, validation_data = (X_test_FC, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(X_test_FC[5000].reshape(32,32), cmap = 'gray') #image, reshape size, cmap\n",
    "plt.show()\n",
    "print(np.argmax(model_FC.predict(X_test_FC[5000].reshape(1,1024))))\n",
    "\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(X_test_FC[9876].reshape(32,32), cmap = 'gray') #image, reshape size, cmap\n",
    "plt.show()\n",
    "print(np.argmax(model_FC.predict(X_test_FC[9876].reshape(1,1024))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a developed a very basic FC network that easily gives us an accuracy of 56% which is not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#Set model hyperparameters\n",
    "num_classes = 10\n",
    "\n",
    "#Define the layers of the model\n",
    "model_CNN = Sequential()\n",
    "\n",
    "#1. Conv Layer\n",
    "model_CNN.add(Conv2D(32, kernel_size = (3,3), activation = 'relu', input_shape = input_shape))\n",
    "\n",
    "#2. Conv Layer\n",
    "model_CNN.add(Conv2D(64, kernel_size = (3,3), activation = 'relu', input_shape = input_shape))\n",
    "\n",
    "#3. MaxPooling Layer\n",
    "model_CNN.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#4. Dropout this prevents model from overfitting\n",
    "model_CNN.add(Dropout(0.25))\n",
    "\n",
    "#5. Flatten Layer\n",
    "model_CNN.add(Flatten())\n",
    "\n",
    "#6. Fully Connected Layer\n",
    "model_CNN.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "#7. Dropout\n",
    "model_CNN.add(Dropout(0.5))\n",
    "\n",
    "#8. Fully Connected Layer\n",
    "model_CNN.add(Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Loss, Optimizer, Metrics for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tensorboard for training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the tensorboard callback for visualization of training\n",
    "\n",
    "#For COLAB\n",
    "#Import tensorboard colab modules for creating a tensorboard call back which will pass in model.fit function\n",
    "\n",
    "#from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
    "#from time import time\n",
    "\n",
    "#Tensorboard callback is going to be added to model.fit function to draw graphs of loss values after every epoch\n",
    "#tbc = TensorBoardColab()\n",
    "\n",
    "#For KAGGLE\n",
    "# Load the extension and start TensorBoard\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n",
    "import tensorflow as tf\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Early stopping and Model checkpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is this and why do we need them ?**\n",
    "\n",
    "While training a NN, we often come across the problem of finding the right no. of training epochs to use. \n",
    "* Too many epochs - Training dataset is overfit\n",
    "* Too few epochs - Training dataset is underfit\n",
    "\n",
    "Early stopping is a method that allows us to specify an arbitrary large no. of training epochs and stop training once the model performance stops improving on validation set.\n",
    "\n",
    "While we do this, we want the model to save our best weights this is where Model checkpoint comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#Adding Early Stopping function to the Fit function is going to stop the training. \n",
    "#That is, when the validation loss doesn't change even by '0.001' for more than 10 continuous epochs\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, patience = 10)\n",
    "\n",
    "#Adding Model Checkpoint callback to the fit function is going to save the weights whenever the val_loss achieves a new low value\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('svhn_cnn_checkpoint_{epoch:02d}_loss{val_loss:.4f}.h5',\n",
    "                                  monitor = 'val_loss',\n",
    "                                  verbose = 1,\n",
    "                                  save_best_only = True,\n",
    "                                  save_weights_only = True,\n",
    "                                  mode = 'auto',\n",
    "                                  period = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model to dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.fit(X_train_CNN, y_train,\n",
    "             batch_size = 128,\n",
    "             epochs = 10,\n",
    "             verbose = 1,\n",
    "             validation_data = (X_test_CNN, y_test))\n",
    "             #callbacks = [tensorboard_callback, early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN improves our accuracy from 56% to 89%. Thereby proving CNN performs better than FC for Computer Vision problems.  Now that we have fitted the model, lets also evaluate test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_CNN.evaluate(X_test_CNN, y_test)\n",
    "print('Test Loss: ', score[0])\n",
    "print('Test Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets visualize some predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(X_test_CNN[30].reshape(32,32), cmap = 'gray') #image, reshape size, cmap\n",
    "plt.show()\n",
    "print(np.argmax(model_CNN.predict(X_test_CNN[30].reshape(1,32,32,1))))\n",
    "\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(X_test_CNN[50].reshape(32,32), cmap = 'gray')\n",
    "plt.show()\n",
    "print(np.argmax(model_CNN.predict(X_test_CNN[50].reshape(1,32,32,1))))\n",
    "\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(X_test_CNN[100].reshape(32,32), cmap = 'gray') #image, reshape size, cmap\n",
    "plt.show()\n",
    "print(np.argmax(model_CNN.predict(X_test_CNN[100].reshape(1,32,32,1))))\n",
    "\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(X_test_CNN[230].reshape(32,32), cmap = 'gray') #image, reshape size, cmap\n",
    "plt.show()\n",
    "print(np.argmax(model_CNN.predict(X_test_CNN[230].reshape(1,32,32,1))))\n",
    "\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(X_test_CNN[1000].reshape(32,32), cmap = 'gray') #image, reshape size, cmap\n",
    "plt.show()\n",
    "print(np.argmax(model_CNN.predict(X_test_CNN[1000].reshape(1,32,32,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the trained weights and model in .h5 file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.save('./cnn_svhn.h5')\n",
    "model_CNN.save_weights('./cnn_svhn_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding more layers into this model would further improve accuracy.**\n",
    "\n",
    "**This kernel is a work in progress...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
